{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZSQp9y_JfK2S",
        "tHSV3fF-fXXI",
        "vYODC-aagDqD",
        "lYbjJNb2gXj5",
        "YRZ_hq6Eg1H3",
        "J4pY7ZAYg7c9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"0\"></a>\n",
        "# üéØ Netflix Recommendation System ‚Äì Hands-on AI Workshop\n",
        "\n",
        "üí° Have you ever wondered how Netflix *knows* exactly what to recommend you after a binge night? Or how it's smart enough to suggest ‚Äúlight comedy‚Äù after a breakup movie?\n",
        "\n",
        "Today, you'll get to build a mini-version of such a system ‚Äî all using **Traditional AI**!\n",
        "\n",
        "---------\n",
        "\n",
        "In this project, we're using a dataset from kaggle for Netflix Data and then using various machine learning methods (which will be explained below) to make a recommendation system/function based on a movie or TV show.\n",
        "Let's begin!\n",
        "\n",
        "### In this notebook, we will cover:\n",
        "* [Overview](#0)\n",
        "* [Environment Setup & Data Set Loading](#1)\n",
        "* [Data Exploration and Adjustment](#2)\n",
        "* [Text Preprocessing](#3)\n",
        "* [Text Vectorization and Similarity Calculation](#4)\n",
        "* [Recommendation Function](#5)\n",
        "* [Final Recommendation Examples & Output](#6)"
      ],
      "metadata": {
        "id": "RpZHtZQVUhOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîß Pre-requisites & Setup"
      ],
      "metadata": {
        "id": "Z2rl9dWgeYyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Before we begin, make sure you have the following:\n",
        "\n",
        "1. ‚úÖ A Google Account (for opening Google Colab)\n",
        "2. ‚úÖ Basic Python knowledge (loops, functions, pandas)\n",
        "3. ‚úÖ This workshop notebook:\n",
        "   üìé [Click here to open the Colab](https://colab.research.google.com/github/NamVr/Netflix-Recommendation-System/blob/main/notebook.ipynb)\n",
        "\n",
        "üíª GitHub Repo: [github.com/NamVr/Netflix-Recommendation-System](https://github.com/NamVr/Netflix-Recommendation-System)\n",
        "\n",
        "üì¶ No local setup needed ‚Äî all code runs in the browser.\n",
        "\n",
        "> üöÄ ***DIY - Do It Yourself Challenge:*** Take up the courage and try to do it yourself instead of copying all code from colab. Only take help when needed."
      ],
      "metadata": {
        "id": "QUvi0xnepNEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>üì∏ Workshop Resources</h2>\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th><a href=\"https://colab.research.google.com/github/NamVr/Netflix-Recommendation-System/blob/main/notebook.ipynb\">üîó Google Colab</a></th>\n",
        "    <th>&nbsp;&nbsp;&nbsp;</th>\n",
        "    <th><a href=\"https://github.com/NamVr/Netflix-Recommendation-System/\">üêô GitHub Repo</a></th>\n",
        "    <th>&nbsp;&nbsp;&nbsp;</th>\n",
        "    <th><a href=\"https://linkedin.com/in/namanvrati\">üíº LinkedIn</a></th>\n",
        "    <th>&nbsp;&nbsp;&nbsp;</th>\n",
        "    <th><a href=\"https://forms.gle/1dMRPY8hisXzBWNRA\">üìù Feedback Form</a></th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><img src=\"https://api.qrserver.com/v1/create-qr-code/?size=120x120&data=https://colab.research.google.com/github/NamVr/Netflix-Recommendation-System/blob/main/notebook.ipynb\"></td>\n",
        "    <td></td>\n",
        "    <td><img src=\"https://api.qrserver.com/v1/create-qr-code/?size=120x120&data=https://github.com/NamVr/Netflix-Recommendation-System/\"></td>\n",
        "    <td></td>\n",
        "    <td><img src=\"https://api.qrserver.com/v1/create-qr-code/?size=120x120&data=https://linkedin.com/in/namanvrati\"></td>\n",
        "    <td></td>\n",
        "    <td><img src=\"https://api.qrserver.com/v1/create-qr-code/?size=120x120&data=https://forms.gle/1dMRPY8hisXzBWNRA\"></td>\n",
        "  </tr>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "uxhamyQQn456"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"1\"></a>\n",
        "# 1.1 Section 1\n",
        "## Environment Setup & Data Set Loading\n"
      ],
      "metadata": {
        "id": "ZSQp9y_JfK2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now setting up our coding environment! If you're running this in Google Colab, you already have most libraries installed. But let's ensure they're ready.\n"
      ],
      "metadata": {
        "id": "2eDY7g8YBaTz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-YCQWrnT8Tc"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install numpy pandas scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset as (df) as original and (data) will be processed.\n",
        "df = pd.read_csv(\"/content/netflixData.csv\")\n",
        "data = df"
      ],
      "metadata": {
        "id": "3qg1IVOgooIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"2\"></a>\n",
        "# 1.2 Section 2\n",
        "## Data Exploration and Adjustment"
      ],
      "metadata": {
        "id": "tHSV3fF-fXXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore the dataset to understand what kind of content Netflix provides and how we can use that for recommendations."
      ],
      "metadata": {
        "id": "pqEyNJKfBtlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "rzyugCytVzNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe the DataSet (DataFrame.describe())\n",
        "data.describe(include='all')"
      ],
      "metadata": {
        "id": "8QO3Jmi9pQGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Data Set Info (DataFrame.info())\n",
        "data.info()"
      ],
      "metadata": {
        "id": "R7p-ftdFpgY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "4jhm6zIwfvBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant columns only, drop other columns!\n",
        "data = data[[\"Title\", \"Description\", \"Director\", \"Cast\", \"Genres\", \"Rating\", \"Content Type\"]]\n",
        "data.set_index(\"Title\", inplace=True)\n",
        "\n",
        "# Practically we should drop NA or NaN values BUT we see that almost 30% of the\n",
        "# dataset will be lost. Directors have 2064 NaN values, which is almost 30%\n",
        "# of the entire dataset. Instead, we are going to replace NaN values with an\n",
        "# empty string and add checks.\n",
        "data.fillna(\"\", inplace=True)\n",
        "\n",
        "# Display adjusted dataset.\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Vg7MLuiMfwoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"3\"></a>\n",
        "# 1.3 Section 3\n",
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "vYODC-aagDqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßπ We now clean the data to make it machine-friendly:\n",
        "- Remove punctuation\n",
        "- Convert to lowercase\n",
        "- Combine relevant features"
      ],
      "metadata": {
        "id": "VCK-2aHIB0eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating text preprocessing functions such as:\n",
        "\n",
        "# seperate(texts: str) -> str:\n",
        "# Creates a list, then splits given string by \",\", trims additional spaces.\n",
        "# Returns the list joint together with ' ' (spaces)\n",
        "def separate(texts):\n",
        "    t = []\n",
        "    for text in texts.split(','):\n",
        "        t.append(text.replace(' ', '').lower())\n",
        "    return ' '.join(t)\n",
        "\n",
        "# remove_space(texts: str) -> str:\n",
        "# Removes unnecessary spaces from the string and returns it.\n",
        "def remove_space(texts):\n",
        "    return texts.replace(' ', '').lower()\n",
        "\n",
        "# remove_punc(texts: str) -> str:\n",
        "# Removes punctuations from the texts, converts text to lower case using\n",
        "# lower() and then returns it.\n",
        "def remove_punc(texts):\n",
        "    return texts.translate(str.maketrans('','',string.punctuation)).lower()"
      ],
      "metadata": {
        "id": "SMxCJL9assah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.apply(def identifier)\n",
        "# Uses the selected data and applies the given function on it.\n",
        "# We are using apply to format text to suit our algorithm.\n",
        "\n",
        "data['Content Type'] = data['Content Type'].apply(remove_space)\n",
        "data['Director'] = data['Director'].apply(separate)\n",
        "data['Cast'] = data['Cast'].apply(separate)\n",
        "data['Rating'] = data['Rating'].apply(remove_space)\n",
        "data['Genres'] = data['Genres'].apply(separate)\n",
        "data['Description'] = data['Description'].apply(remove_punc)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "z0QWV7wPsuH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we're creating a new column 'bag_of_words' in the Data Set\n",
        "# Each row contains a concatenated string of non-empty values from all other\n",
        "# columns in that row. It's a common preprocessing step when working with text\n",
        "# data to create a bag-of-words representation.\n",
        "data['bag_of_words'] = ''\n",
        "\n",
        "# Combine all the words into 1 column\n",
        "for i, row in enumerate(data.iterrows()):\n",
        "    string = ''\n",
        "    for col in data.columns:\n",
        "        if row[1][col] == '':\n",
        "            continue\n",
        "        else:\n",
        "            string += row[1][col] + ' '\n",
        "            data['bag_of_words'][i] = string.strip()\n",
        "\n",
        "# enumerate is a built-in Python function that adds a counter to an iterable\n",
        "# (e.g., a list, tuple, or string) and returns it as an enumerate object.\n",
        "# The enumerate object contains pairs of index and corresponding value from\n",
        "# the original iterable. It is commonly used in loops to iterate over both the\n",
        "# elements and their indices simultaneously.\n",
        "\n",
        "data.drop(data.columns[:-1], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "43tk6RfxwLjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"4\"></a>\n",
        "# 1.4 Section 4\n",
        "## Text Vectorization and Similarity Calculation\n"
      ],
      "metadata": {
        "id": "lYbjJNb2gXj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF** stands for Term Frequency ‚Äî Inverse Document Frequency. It tells the importance of a word. In a nutshell, The word that appear more frequently in the corpus, it will be considered less importance, hence the tfidf score will be lower. It goes the opposite way with less frequent word.\n",
        "\n",
        "----\n",
        "\n",
        "We now convert text into numerical form using **TF-IDF** ‚Äî a method that understands importance of words.\n",
        "Then, we calculate **Cosine Similarity**, which finds items that are ‚Äúclose‚Äù to each other in terms of meaning."
      ],
      "metadata": {
        "id": "913O-xZSXOGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer is a class provided by scikit-learn for converting a\n",
        "# collection of raw documents (text) into a matrix of TF-IDF features.\n",
        "# TF-IDF stands for Term Frequency-Inverse Document Frequency and is a\n",
        "# numerical statistic used to reflect the importance of a word in a document\n",
        "# relative to a collection of documents (corpus).\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# cosine_similarity is a function in scikit-learn that computes the cosine\n",
        "# similarity between vectors. In the context of NLP, these vectors are often\n",
        "# the rows of a matrix representing documents in a high-dimensional space.\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "HbYZ7z5Yw_sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidVectorizer is initialized in tfid variable.\n",
        "tfid = TfidfVectorizer()\n",
        "\n",
        "# Fit and Transform: The fit_transform method of the TfidfVectorizer is then\n",
        "# used to convert the 'bag_of_words' column of your DataFrame (data) into a\n",
        "# TF-IDF matrix. The result, stored in tfid_matrix, is a sparse matrix where\n",
        "# each row corresponds to a document (in this case, each row of the\n",
        "# 'bag_of_words' column), and each column corresponds to a unique word in the\n",
        "# entire dataset. The values in the matrix represent the TF-IDF scores for each\n",
        "# word in each document.\n",
        "tfid_matrix = tfid.fit_transform(data['bag_of_words'])"
      ],
      "metadata": {
        "id": "kbg2tMOqWltI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfid_matrix"
      ],
      "metadata": {
        "id": "Fm58NtYexVUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The cosine_similarity function takes two matrices as input and computes the\n",
        "# cosine similarity between corresponding rows. In this case, both matrices\n",
        "# provided are the same (tfid_matrix), so the resulting cosine_sim matrix will\n",
        "# be a square matrix where each entry [i, j] represents the cosine similarity\n",
        "# between the i-th and j-th rows (documents) in the original dataset.\n",
        "cosine_sim = cosine_similarity(tfid_matrix, tfid_matrix)\n",
        "cosine_sim"
      ],
      "metadata": {
        "id": "3DpcU8PdxSLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5\"></a>\n",
        "# 1.5 Section 5\n",
        "## Recommendation Function"
      ],
      "metadata": {
        "id": "YRZ_hq6Eg1H3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now build our recommender engine! üéØ\n",
        "\n",
        "We'll use the similarity scores to find movies most similar to the one the user searches.\n"
      ],
      "metadata": {
        "id": "fduiXwRACORU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating recommendation based on Title/Content Type.\n",
        "# Many other recommendation models can be made after this step :)\n",
        "final_df = df[['Title', 'Content Type']]\n",
        "\n",
        "def recommendation(title, total_result=5):\n",
        "    # Get the index\n",
        "    idx = final_df[final_df['Title'] == title].index[0]\n",
        "\n",
        "    # Create a new column for similarity, the value is different for each title you input\n",
        "    final_df['Similarity'] = cosine_sim[idx]\n",
        "    sort_final_df = final_df.sort_values(by='Similarity', ascending=False)[1:total_result+1]\n",
        "\n",
        "    # Is the title a movie or tv show?\n",
        "    movies = sort_final_df['Title'][sort_final_df['Content Type'] == 'Movie']\n",
        "    tv_shows = sort_final_df['Title'][sort_final_df['Content Type'] == 'TV Show']\n",
        "\n",
        "    if len(movies) != 0:\n",
        "        print('Similar Movie(s) list:')\n",
        "        for i, movie in enumerate(movies):\n",
        "            print('{}. {}'.format(i+1, movie))\n",
        "        print()\n",
        "    else:\n",
        "        print('Similar Movie(s) list:')\n",
        "        print('-\\n')\n",
        "\n",
        "    if len(tv_shows) != 0:\n",
        "        print('Similar TV_show(s) list:')\n",
        "        for i, tv_show in enumerate(tv_shows):\n",
        "            print('{}. {}'.format(i+1, tv_show))\n",
        "    else:\n",
        "        print('Similar TV_show(s) list:')\n",
        "        print('-')"
      ],
      "metadata": {
        "id": "PnQ_6Zeyg4j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"6\"></a>\n",
        "# 1.6 Section 6\n",
        "## Final Recommendation Examples & Output"
      ],
      "metadata": {
        "id": "J4pY7ZAYg7c9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üì¶ Here's a sample of recommendations generated by our system.\n",
        "Try changing the movie title and see how results differ!\n"
      ],
      "metadata": {
        "id": "28Qq7xJACTA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations for the movie \"Stranger Things\"\n",
        "recommendation(\"Stranger Things\")"
      ],
      "metadata": {
        "id": "EeMsJJpeg5Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Result\n",
        "# Get recommendation by inputting movie name.\n",
        "\n",
        "n = input(\"Enter Movie/TV Show Name: \")\n",
        "recommendation(n)"
      ],
      "metadata": {
        "id": "P5vBuUuk2FyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "# üìé **Conclusion:**\n",
        "\n",
        "I hope you enjoyed this session. If you enjoyed this, **please share on LinkedIn and tag me + GDG** ‚Äî let's inspire more folks to explore AI/ML!\n",
        "\n",
        "Connect with me on LinkedIn: https://linkedin.com/in/namanvrati <br>\n",
        "Email me for doubts: info@namanvrati.me <br> <br>\n",
        "\n",
        "---\n",
        "\n",
        "### Wohoo! Thanks :)\n"
      ],
      "metadata": {
        "id": "QQBbiJL23ci_"
      }
    }
  ]
}